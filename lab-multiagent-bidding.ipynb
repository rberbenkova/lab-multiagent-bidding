{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-poMPpjGDbS"
      },
      "source": [
        "# Lab | Multi-agent bidding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WCPtzPmGDbU"
      },
      "source": [
        "# Multi-agent decentralized speaker selection\n",
        "\n",
        "This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent's bid is the highest gets to speak.\n",
        "\n",
        "We will show how to do this in the example below that showcases a fictitious presidential debate."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No fixed turn order. Each agent bids to speak; highest bid talks next.\n",
        "\n",
        "**1. Core idea of decentralized speaker selection**\n",
        "\n",
        "We have multiple agents, e.g.:\n",
        "\n",
        "Agent A → “Candidate Alpha”\n",
        "\n",
        "Agent B → “Candidate Beta”\n",
        "\n",
        "Agent C → “Moderator” (optional or treated as just another agent)\n",
        "\n",
        "At each step:\n",
        "\n",
        "Everyone sees the current debate history.\n",
        "\n",
        "Each agent internally decides:\n",
        "\n",
        "How much do I want to speak now? → bid score\n",
        "\n",
        "What would I say? → proposed utterance\n",
        "\n",
        "All agents submit (bid, utterance).\n",
        "\n",
        "\n",
        "The system picks the agent with the highest bid.\n",
        "\n",
        "That agent’s utterance is appended to the conversation.\n",
        "\n",
        "Repeat.\n",
        "\n",
        "No fixed order. The “right” agent speaks when it has the strongest reason.\n",
        "\n",
        "**2. Simple design of the agents**\n",
        "\n",
        "Each agent has:\n",
        "\n",
        "- a name\n",
        "\n",
        "- a role / persona (e.g. “environment-focused candidate”)\n",
        "\n",
        "- an LLM (or stub function) that:\n",
        "\n",
        "   - computes a bid given the conversation so far\n",
        "\n",
        "   - generates a message if it wins"
      ],
      "metadata": {
        "id": "2G2lDJtUHonh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8190PnGDbU"
      },
      "source": [
        "## Import LangChain related modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n",
        "!pip install langchain_community\n",
        "!pip install -q \"langchain>=0.2.0\" \"langchain-core>=0.2.0\" \"langchain-openai>=0.1.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQXcoFWnGSGg",
        "outputId": "89db7a08-9834-401f-c018-65fdc013f0c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.35)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.3.80)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.4.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Collecting langchain-core<2.0.0,>=1.0.1 (from langchain_community)\n",
            "  Using cached langchain_core-1.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Using cached langchain_core-1.0.7-py3-none-any.whl (472 kB)\n",
            "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: langchain-core, langchain-text-splitters\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 1.0.7 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.7 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.7 langchain-text-splitters-1.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, List\n",
        "import tenacity\n",
        "from langchain.output_parsers import RegexParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    PromptTemplate\n",
        ")\n",
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "mwfjCqjlGSE-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6-zMILOwGDbV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "YaNZ5WE_GDbW"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKxdXC1jGDbW"
      },
      "source": [
        "## `DialogueAgent` and `DialogueSimulator` classes\n",
        "We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Dungeons & Dragons](https://python.langchain.com/en/latest/use_cases/agent_simulations/multi_player_dnd.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vk5hVBMKGDbW"
      },
      "outputs": [],
      "source": [
        "## DialogueAgent - one participant in the conversation\n",
        "# name: a label like \"Candidate Alpha\" or \"Moderator\"\n",
        "# system_message: the role/instructions for this agent (e.g. \"You are a climate-focused candidate...\")\n",
        "# model: the LLM used for this agent (ChatOpenAI)\n",
        "# self.prefix = f\"{self.name}: \": how this agent marks its own lines, e.g. \"Candidate Alpha:\"\n",
        "# self.reset(): initialize its internal conversation memory\n",
        "\n",
        "class DialogueAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        system_message: SystemMessage,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        self.name = name\n",
        "        self.system_message = system_message\n",
        "        self.model = model\n",
        "        self.prefix = f\"{self.name}: \"\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.message_history = [\"Here is the conversation so far.\"]\n",
        "    # Each agent keeps its own copy of the conversation as a list of strings (message_history)\n",
        "    # On reset, we start with a single \"header\" string: \"Here is the conversation so far.\"\n",
        "    # Later, messages like \"Alice: Hi\" or \"Bob: Hello\" get appended to the list\n",
        "\n",
        "\n",
        "    # How the agent speaks\n",
        "    def send(self) -> str:\n",
        "        \"\"\"\n",
        "        Applies the chatmodel to the message history\n",
        "        and returns the message string\n",
        "        \"\"\"\n",
        "        message = self.model.invoke(\n",
        "            [\n",
        "                self.system_message,\n",
        "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
        "            ]\n",
        "        )\n",
        "        return message.content\n",
        "    # It calls the model with two messages:\n",
        "    # self.system_message: the \"you are X, have like Y\" instructions\n",
        "    # HumanMessage(...): a big string made by joining:\n",
        "      # all past conversation lines in message_history\n",
        "      # plus one more line: self.prefix (e.g. \"Candidate Alpha:\"), telling the model it's this agent's turn to speak\n",
        "      # self.model.invoke([...]) asks the LLM to generate the next message\n",
        "      # message.content is the raw text the model returns\n",
        "      # send() returns that text to the caller (e.g. the simulator)\n",
        "\n",
        "\n",
        "\n",
        "    def receive(self, name: str, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Concatenates {message} spoken by {name} into message history\n",
        "        \"\"\"\n",
        "        self.message_history.append(f\"{name}: {message}\")\n",
        "    # This is how the agent listens/ updates its memory\n",
        "    # Whenever anyone speaks, we call receive() on every agent\n",
        "    # It append a new line like: \"Candidate Beta: I disagree with that point.\"\n",
        "    # to message_history, so this agent has a full log of who said what.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DialogueSimulator - manages many agents and turn-talking\n",
        "# agents: list of all DialogueAgent objects (candidates, moderator, etc.)\n",
        "# self.step: simple counter for how many turns have passed\n",
        "# selection_function: a function you provide that decides who speaks next\n",
        "    #  it takes (current_step, agents) and returns an index into self.agents\n",
        "    #  This is where your bidding/decentralized speaker selection logic will go\n",
        "\n",
        "class DialogueSimulator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        agents: List[DialogueAgent],\n",
        "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
        "    ) -> None:\n",
        "        self.agents = agents\n",
        "        self._step = 0\n",
        "        self.select_next_speaker = selection_function\n",
        "\n",
        "    def reset(self):\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "    # Reset the whole simulation:\n",
        "    # Calls reset() on every agent - clears their message_history\n",
        "\n",
        "\n",
        "    def inject(self, name: str, message: str):\n",
        "        \"\"\"\n",
        "        Initiates the conversation with a {message} from {name}\n",
        "        \"\"\"\n",
        "        for agent in self.agents:\n",
        "            agent.receive(name, message)\n",
        "\n",
        "        # increment time\n",
        "        self._step += 1\n",
        "    # Used to start the conversation (e.g. moderator's opening question)\n",
        "        # name: who is speaking (e.g. \"Moderator\")\n",
        "        # message: what they say (e.g. \"Welcome to the debate...\")\n",
        "        # Calls receive(name, message) on all agents, so everyone sees the same initial message in their histories\n",
        "        # Increments _step (we've had one interaction)\n",
        "\n",
        "    def step(self) -> tuple[str, str]:\n",
        "        # 1. choose the next speaker\n",
        "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
        "        speaker = self.agents[speaker_idx]\n",
        "        # calls self.select_next_speaker(self._step, self.agents)\n",
        "        # that function returns an index, eg. 1 - second agent\n",
        "        # speaker = slef.agents[speaker_idx] picks the agent object\n",
        "\n",
        "        # 2. next speaker sends message\n",
        "        message = speaker.send()\n",
        "        # this alls the LLM with that agent's system_message and message_history and returns the generated text\n",
        "\n",
        "        # 3. everyone receives message\n",
        "        # for each receiver in self.agents, call:\n",
        "        for receiver in self.agents:\n",
        "            receiver.receive(speaker.name, message) # everyone updates their history with this new line\n",
        "\n",
        "        # 4. increment time and return\n",
        "        self._step += 1\n",
        "\n",
        "        return speaker.name, message  # returns (speaker.name, message) so you can print/log it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3cmQ35eGDbX"
      },
      "source": [
        "## `BiddingDialogueAgent` class\n",
        "We define a subclass of `DialogueAgent` that has a `bid()` method that produces a bid given the message history and the most recent message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fiu5yFX5GDbX"
      },
      "outputs": [],
      "source": [
        "class BiddingDialogueAgent(DialogueAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        system_message: SystemMessage,\n",
        "        bidding_template: PromptTemplate,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        super().__init__(name, system_message, model)\n",
        "        self.bidding_template = bidding_template\n",
        "# This inherits from DialogueAgent, so it has: name; system_message; model; message_history, send, receive, etc\n",
        "# adds a new attribute: self.bidding_template: a PromptTemplate that tells the model how to decide its bid to speak\n",
        "\n",
        "    def bid(self) -> str:\n",
        "        \"\"\"\n",
        "        Asks the chat model to output a bid to speak\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(  # Build the prompt for bidding\n",
        "            input_variables=[\"message_history\", \"recent_message\"],\n",
        "            template=self.bidding_template,\n",
        "        ).format(\n",
        "            message_history=\"\\n\".join(self.message_history),\n",
        "            recent_message=self.message_history[-1],\n",
        "        )\n",
        "        # The intent here is:\n",
        "        # take the conversation so far: \"\"\\n\".join(self.message_history)\n",
        "        # take the last message: self.message_history[-1]\n",
        "        # inject them into a bidding_template that might say something like:\n",
        "              # You are {name}.\n",
        "              # Here is the conversation so far:{message_history}\n",
        "              # The most recent message is: {recent_message}\n",
        "              # On a scale from 0 to 1, how important is it that you speak next?\n",
        "              # Respond with only a number\n",
        "\n",
        "\n",
        "\n",
        "        bid_string = self.model.invoke([SystemMessage(content=prompt)]).content\n",
        "        # call the model to get the bid\n",
        "        # sends a single SystemMessage whose content is this bidding prompt\n",
        "        # LLM responds with some text. eg. \"0.73\"\n",
        "        # that text is stored as bid_string\n",
        "\n",
        "        return bid_string # return the bid as a string\n",
        "        # the idea is that the selection functiton (speaker chooser) will later\n",
        "        # parse this into a number and compare bids between agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpRtO3KtGDbY"
      },
      "source": [
        "## Define participants and debate topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CSV8vjNPGDbY"
      },
      "outputs": [],
      "source": [
        "character_names = [\"Donald Trump\", \"Kanye West\", \"Elizabeth Warren\"]\n",
        "topic = \"transcontinental high speed rail\"\n",
        "word_limit = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoO8Uf2TGDbY"
      },
      "source": [
        "## Generate system messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "descriptor_model = ChatOpenAI(temperature=1.0)\n"
      ],
      "metadata": {
        "id": "FXo82_MSk1mb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aATthGlGDbY",
        "outputId": "b2c08775-fb10-4a60-d66e-04cf94cd124c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2718857050.py:23: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  character_description = ChatOpenAI(temperature=1.0)(\n"
          ]
        }
      ],
      "source": [
        "game_description = f\"\"\"Here is the topic for the presidential debate: {topic}.\n",
        "The presidential candidates are: {', '.join(character_names)}.\"\"\"\n",
        "\n",
        "player_descriptor_system_message = SystemMessage(\n",
        "    content=\"You can add detail to the description of each presidential candidate.\"\n",
        ")\n",
        "# this is a system message for an LLM whose job is to invent creative descriptions of each candidate\n",
        "\n",
        "def generate_character_description(character_name):\n",
        "    character_specifier_prompt = [\n",
        "        player_descriptor_system_message,\n",
        "        HumanMessage(\n",
        "            content=f\"\"\"{game_description}\n",
        "            Please reply with a creative description of the presidential candidate, {character_name}, in {word_limit} words or less, that emphasizes their personalities.\n",
        "            Speak directly to {character_name}.\n",
        "            Do not add anything else.\"\"\"\n",
        "        ),\n",
        "    ]\n",
        "  # builds a prompt: the system message;\n",
        "  # and a human message (includes game descr., asks for short description, tells model to speak directly to that character, says DO not do anything else)\n",
        "\n",
        "\n",
        "    character_description = ChatOpenAI(temperature=1.0)(\n",
        "        character_specifier_prompt\n",
        "    ).content\n",
        "    return character_description\n",
        "\n",
        "# Turn that into a header for each character\n",
        "def generate_character_header(character_name, character_description):\n",
        "    return f\"\"\"{game_description}\n",
        "Your name is {character_name}.\n",
        "You are a presidential candidate.\n",
        "Your description is as follows: {character_description}\n",
        "You are debating the topic: {topic}.\n",
        "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
        "\"\"\"\n",
        "# this wraps; the game description, the candidate name, the generated description, the debate topic and the goal (make voters think you are the best)\n",
        "# it becomes the base context for the agent\n",
        "\n",
        "\n",
        "# turns the heade into the agent's system message\n",
        "def generate_character_system_message(character_name, character_header):\n",
        "    return SystemMessage(\n",
        "        content=(\n",
        "            f\"\"\"{character_header}\n",
        "You will speak in the style of {character_name}, and exaggerate their personality.\n",
        "You will come up with creative ideas related to {topic}.\n",
        "Do not say the same things over and over again.\n",
        "Speak in the first person from the perspective of {character_name}\n",
        "For describing your own body movements, wrap your description in '*'.\n",
        "Do not change roles!\n",
        "Do not speak from the perspective of anyone else.\n",
        "Speak only from the perspective of {character_name}.\n",
        "Stop speaking the moment you finish speaking from your perspective.\n",
        "Never forget to keep your response to {word_limit} words!\n",
        "Do not add anything else.\n",
        "    \"\"\"\n",
        "        )\n",
        "    )\n",
        "# this become the system prompt used by the debating agents\n",
        "# it tells each one to: stay in character, exaggerate personality, talk only about the topic, not repeat themselves\n",
        "#... use *...* around body movements, never switch roles, keep responses under word_limit words\n",
        "\n",
        "\n",
        "# building descriptions, headers, and system messages for all candidates\n",
        "character_descriptions = [\n",
        "    generate_character_description(character_name) for character_name in character_names\n",
        "] # lists of text descriptions (one per candidate)\n",
        "character_headers = [\n",
        "    generate_character_header(character_name, character_description)\n",
        "    for character_name, character_description in zip(\n",
        "        character_names, character_descriptions\n",
        "    )\n",
        "] # list of headers (one per candidate)\n",
        "\n",
        "character_system_messages = [\n",
        "    generate_character_system_message(character_name, character_header)\n",
        "    for character_name, character_header in zip(character_names, character_headers)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUCMyl9YGDbZ",
        "outputId": "d07ecaa8-d7d2-45fc-e8f5-41b14305461f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Donald Trump Description:\n",
            "\n",
            "Donald Trump, known for his bold and often controversial statements. You're unapologetically confident and never shy away from a debate. Your larger-than-life personality commands attention, and you thrive on stirring things up. Your determination and resilience have made you a formidable force in politics.\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Donald Trump.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Donald Trump, known for his bold and often controversial statements. You're unapologetically confident and never shy away from a debate. Your larger-than-life personality commands attention, and you thrive on stirring things up. Your determination and resilience have made you a formidable force in politics.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Donald Trump.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Donald Trump, known for his bold and often controversial statements. You're unapologetically confident and never shy away from a debate. Your larger-than-life personality commands attention, and you thrive on stirring things up. Your determination and resilience have made you a formidable force in politics.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Donald Trump, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Donald Trump\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Donald Trump.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n",
            "\n",
            "\n",
            "Kanye West Description:\n",
            "\n",
            "Kanye West, a visionary artist and provocateur, your passion and creativity are undeniable. Your boldness and willingness to push boundaries have inspired many. As a presidential candidate, can you harness this energy to tackle complex issues like transcontinental high speed rail with innovative solutions?\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Kanye West.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Kanye West, a visionary artist and provocateur, your passion and creativity are undeniable. Your boldness and willingness to push boundaries have inspired many. As a presidential candidate, can you harness this energy to tackle complex issues like transcontinental high speed rail with innovative solutions?\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Kanye West.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Kanye West, a visionary artist and provocateur, your passion and creativity are undeniable. Your boldness and willingness to push boundaries have inspired many. As a presidential candidate, can you harness this energy to tackle complex issues like transcontinental high speed rail with innovative solutions?\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Kanye West, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Kanye West\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Kanye West.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n",
            "\n",
            "\n",
            "Elizabeth Warren Description:\n",
            "\n",
            "Elizabeth Warren, known for her fierce advocacy for consumer rights and economic equality, your unwavering determination and sharp intellect shine through in every debate. Your passion for justice and fighting for the middle class resonates deeply with many Americans.\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Elizabeth Warren.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Elizabeth Warren, known for her fierce advocacy for consumer rights and economic equality, your unwavering determination and sharp intellect shine through in every debate. Your passion for justice and fighting for the middle class resonates deeply with many Americans.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Elizabeth Warren.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Elizabeth Warren, known for her fierce advocacy for consumer rights and economic equality, your unwavering determination and sharp intellect shine through in every debate. Your passion for justice and fighting for the middle class resonates deeply with many Americans.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Elizabeth Warren, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Elizabeth Warren\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Elizabeth Warren.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "for (\n",
        "    character_name,\n",
        "    character_description,\n",
        "    character_header,\n",
        "    character_system_message,\n",
        ") in zip(\n",
        "    character_names,\n",
        "    character_descriptions,\n",
        "    character_headers,\n",
        "    character_system_messages,\n",
        "):\n",
        "    print(f\"\\n\\n{character_name} Description:\")\n",
        "    print(f\"\\n{character_description}\")\n",
        "    print(f\"\\n{character_header}\")\n",
        "    print(f\"\\n{character_system_message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkJEIHdGDbZ"
      },
      "source": [
        "## Output parser for bids\n",
        "We ask the agents to output a bid to speak. But since the agents are LLMs that output strings, we need to\n",
        "1. define a format they will produce their outputs in\n",
        "2. parse their outputs\n",
        "\n",
        "We can subclass the [RegexParser](https://github.com/langchain-ai/langchain/blob/master/langchain/output_parsers/regex.py) to implement our own custom output parser for bids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bjOh5bWcGDbZ"
      },
      "outputs": [],
      "source": [
        "# the custom parser class\n",
        "class BidOutputParser(RegexParser):\n",
        "    def get_format_instructions(self) -> str:\n",
        "        return \"Your response should be an integer delimited by angled brackets, like this: <int>.\"\n",
        "# inherits from RegexParser (a LangChain helper that parses LLM output using regular expressions)\n",
        "# get_format_instructions tells the LLM how to format its answer.\n",
        "# when LangChain builds prompts, it will include whatever get_format_instructions() returns\n",
        "# basically telling the model: \"Don't write prose. Just output something like <3> or <10>\"\n",
        "\n",
        "bid_parser = BidOutputParser(\n",
        "    regex=r\"<(\\d+)>\", output_keys=[\"bid\"], default_output_key=\"bid\"\n",
        ")\n",
        "# creating an instance of the parser:\n",
        "# configures how to extract the integer from LLM's output; to capture just digits as the group\n",
        "# output_keys=[\"bid\"] - the expected value should be returned under the key 'bid'\n",
        "# default_output_key=\"bid\" - when parser called, main important value is 'bid'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5lKuAL2GDba"
      },
      "source": [
        "## Generate bidding system message\n",
        "This is inspired by the prompt used in [Generative Agents](https://arxiv.org/pdf/2304.03442.pdf) for using an LLM to determine the importance of memories. This will use the formatting instructions from our `BidOutputParser`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zrofnT2BGDba"
      },
      "outputs": [],
      "source": [
        "# setting up a per-character bidding prompt that tells each candidate how to score the last message on 1-10 scale\n",
        "# and dto output the score in the special <int> format that BidOutputParser expects\n",
        "\n",
        "def generate_character_bidding_template(character_header):\n",
        "    bidding_template = f\"\"\"{character_header}\n",
        "\n",
        "```\n",
        "{{message_history}}\n",
        "```\n",
        "\n",
        "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
        "\n",
        "```\n",
        "{{recent_message}}\n",
        "```\n",
        "\n",
        "{bid_parser.get_format_instructions()}\n",
        "Do nothing else.\n",
        "    \"\"\"\n",
        "    return bidding_template\n",
        "\n",
        "# character_header - persona header built earlier for each candidate, then strings of message_history and recent message\n",
        "# place holders for Lang Chains Prompt Template to fill in\n",
        "\n",
        "# how contradictory this last message to your beliefs is. the higher, the more contradiction\n",
        "# at the end appended\n",
        "\n",
        "\n",
        "# character_bidding_templates\n",
        "character_bidding_templates = [\n",
        "    generate_character_bidding_template(character_header)\n",
        "    for character_header in character_headers\n",
        "]\n",
        "# character headers - list of pre-candidate headers\n",
        "# this list comprehension calls: generate_bidding_template for each header\n",
        "\n",
        "# result is character_bidding_templates - a list of one bidding template per candidate in same order as character_names\n",
        "# this will tyically be zipped with the system messages of BiddingDialogueAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KueFvhkDGDba",
        "outputId": "d6a05e5b-0560-460b-da1e-863da379cea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Donald Trump Bidding Template:\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Donald Trump.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Donald Trump, known for his bold and often controversial statements. You're unapologetically confident and never shy away from a debate. Your larger-than-life personality commands attention, and you thrive on stirring things up. Your determination and resilience have made you a formidable force in politics.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            " \n",
            "\n",
            "```\n",
            "{message_history}\n",
            "```\n",
            "\n",
            "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
            "\n",
            "```\n",
            "{recent_message}\n",
            "```\n",
            "\n",
            "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
            "Do nothing else.\n",
            "    \n",
            "Kanye West Bidding Template:\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Kanye West.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Kanye West, a visionary artist and provocateur, your passion and creativity are undeniable. Your boldness and willingness to push boundaries have inspired many. As a presidential candidate, can you harness this energy to tackle complex issues like transcontinental high speed rail with innovative solutions?\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            " \n",
            "\n",
            "```\n",
            "{message_history}\n",
            "```\n",
            "\n",
            "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
            "\n",
            "```\n",
            "{recent_message}\n",
            "```\n",
            "\n",
            "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
            "Do nothing else.\n",
            "    \n",
            "Elizabeth Warren Bidding Template:\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Elizabeth Warren.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Elizabeth Warren, known for her fierce advocacy for consumer rights and economic equality, your unwavering determination and sharp intellect shine through in every debate. Your passion for justice and fighting for the middle class resonates deeply with many Americans.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            " \n",
            "\n",
            "```\n",
            "{message_history}\n",
            "```\n",
            "\n",
            "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
            "\n",
            "```\n",
            "{recent_message}\n",
            "```\n",
            "\n",
            "Your response should be an integer delimited by angled brackets, like this: <int>.\n",
            "Do nothing else.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "for character_name, bidding_template in zip(\n",
        "    character_names, character_bidding_templates\n",
        "):\n",
        "    print(f\"{character_name} Bidding Template:\")\n",
        "    print(bidding_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tF0pLpGDbb"
      },
      "source": [
        "## Use an LLM to create an elaborate on debate topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwdG3B2NGDbb",
        "outputId": "828ab40d-01e9-49d0-8f9a-ae60d68852ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original topic:\n",
            "transcontinental high speed rail\n",
            "\n",
            "Detailed topic:\n",
            "Candidates, the problem to solve is: \"Design and implement a comprehensive transcontinental high speed rail system that efficiently connects major cities, reduces carbon emissions, and promotes economic growth while addressing infrastructure challenges and public transportation needs.\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "topic_specifier_prompt = [\n",
        "    SystemMessage(content=\"You can make a task more specific.\"),\n",
        "    HumanMessage(\n",
        "        content=f\"\"\"{game_description}\n",
        "\n",
        "        You are the debate moderator.\n",
        "        Please make the debate topic more specific.\n",
        "        Frame the debate topic as a problem to be solved.\n",
        "        Be creative and imaginative.\n",
        "        Please reply with the specified topic in {word_limit} words or less.\n",
        "        Speak directly to the presidential candidates: {*character_names,}.\n",
        "        Do not add anything else.\"\"\"\n",
        "    ),\n",
        "]\n",
        "specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
        "\n",
        "print(f\"Original topic:\\n{topic}\\n\")\n",
        "print(f\"Detailed topic:\\n{specified_topic}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYOh4gaGDbb"
      },
      "source": [
        "## Define the speaker selection function\n",
        "Lastly we will define a speaker selection function `select_next_speaker` that takes each agent's bid and selects the agent with the highest bid (with ties broken randomly).\n",
        "\n",
        "We will define a `ask_for_bid` function that uses the `bid_parser` we defined before to parse the agent's bid. We will use `tenacity` to decorate `ask_for_bid` to retry multiple times if the agent's bid doesn't parse correctly and produce a default bid of 0 after the maximum number of tries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZXTwrIbsGDbc"
      },
      "outputs": [],
      "source": [
        "# this block is all about robustly getting a numeric bid from each agen and then using that\n",
        "# for speaker selection\n",
        "\n",
        "@tenacity.retry(\n",
        "    stop=tenacity.stop_after_attempt(2),\n",
        "    wait=tenacity.wait_none(),  # No waiting time between retries\n",
        "    retry=tenacity.retry_if_exception_type(ValueError),\n",
        "    before_sleep=lambda retry_state: print(\n",
        "        f\"ValueError occurred: {retry_state.outcome.exception()}, retrying...\"\n",
        "    ),\n",
        "    retry_error_callback=lambda retry_state: 0,\n",
        ")  # Default value when all retries are exhausted\n",
        "# wraps ask_for_bid so that: If ValueError happens - retry up to 2 times, not wait b/n retries; print a helpful message before retry\n",
        "\n",
        "def ask_for_bid(agent) -> int:\n",
        "    \"\"\"\n",
        "    Ask for agent bid and parses the bid into the correct format.\n",
        "    \"\"\"\n",
        "    bid_string = agent.bid() # calls the agent's bid() method; agent.bid() expected to return raw string from the LLM <>\n",
        "    bid = int(bid_parser.parse(bid_string)[\"bid\"]) # uses BidOutputParser to parse string and returnst bid: int\n",
        "    return bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Of6RtBVEGDbc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
        "    bids = []\n",
        "    for agent in agents:\n",
        "        bid = ask_for_bid(agent)\n",
        "        bids.append(bid)\n",
        "    # for each agent it calls ask_for_bid(agent):\n",
        "    # calls agent.bid ()\n",
        "    # parser with bid_parser\n",
        "    # returns an integer bid, with tenacity retrying on errors\n",
        "    # collects all bids into a list bids\n",
        "\n",
        "\n",
        "    # convert to numpy array for elementwise comparisons\n",
        "    bids_array = np.array(bids)\n",
        "\n",
        "    # randomly select among multiple agents with the same bid\n",
        "    max_value = np.max(bids) # highest bid\n",
        "    max_indices = np.where(bids == max_value)[0] # intended to get indices of all agents whose bid equals the max\n",
        "    idx = np.random.choice(max_indices) # randomly pick one of those indices\n",
        "\n",
        "\n",
        "\n",
        "    print(\"Bids:\")\n",
        "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
        "        print(f\"\\t{agent.name} bid: {bid}\")\n",
        "        if i == idx:\n",
        "            selected_name = agent.name\n",
        "    print(f\"Selected: {selected_name}\")\n",
        "    print(\"\\n\")\n",
        "    return idx\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8cYL18hGDbc"
      },
      "source": [
        "## Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zm2fQFfeGDbc"
      },
      "outputs": [],
      "source": [
        "characters = []\n",
        "for character_name, character_system_message, bidding_template in zip(\n",
        "    character_names, character_system_messages, character_bidding_templates\n",
        "):\n",
        "    characters.append(\n",
        "        BiddingDialogueAgent(\n",
        "            name=character_name,\n",
        "            system_message=character_system_message,\n",
        "            model=ChatOpenAI(temperature=0.2),\n",
        "            bidding_template=bidding_template,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGP6oB8YGDbd",
        "outputId": "a1b9b2c8-5a2a-43f7-d924-c0a721d9188f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Debate Moderator): Candidates, the problem to solve is: \"Design and implement a comprehensive transcontinental high speed rail system that efficiently connects major cities, reduces carbon emissions, and promotes economic growth while addressing infrastructure challenges and public transportation needs.\"\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 7\n",
            "\tKanye West bid: 1\n",
            "\tElizabeth Warren bid: 1\n",
            "Selected: Donald Trump\n",
            "\n",
            "\n",
            "(Donald Trump): Let me tell you, folks, my high-speed rail plan is going to be tremendous. We're talking about trains that go faster than you've ever seen before. *I gesture dramatically with my hands* It's going to revolutionize travel and boost our economy like never before. Believe me!\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 2\n",
            "\tKanye West bid: 8\n",
            "\tElizabeth Warren bid: 8\n",
            "Selected: Kanye West\n",
            "\n",
            "\n",
            "(Kanye West): *As I step forward confidently, I begin to speak passionately.* Yo, listen up, everyone! My high-speed rail vision is like nothing you've ever seen. Picture this: holographic train cars with live performances, art installations, and sustainable energy sources. It's not just about transportation; it's a cultural experience on the move. *I emphasize my words with animated hand gestures.*\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 7\n",
            "\tKanye West bid: 2\n",
            "\tElizabeth Warren bid: 7\n",
            "Selected: Elizabeth Warren\n",
            "\n",
            "\n",
            "(Elizabeth Warren): *As I stand tall and confident, I address the audience with a determined look.* My fellow Americans, when it comes to transcontinental high-speed rail, we need a plan that not only connects major cities efficiently but also prioritizes sustainability and accessibility for all. Imagine trains powered by renewable energy, offering affordable fares for working families. Let's build a rail system that not only reduces carbon emissions but also creates jobs and boosts local economies along the way. *I gesture with conviction, emphasizing the importance of economic equality and environmental stewardship.*\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 8\n",
            "\tKanye West bid: 2\n",
            "\tElizabeth Warren bid: 1\n",
            "Selected: Donald Trump\n",
            "\n",
            "\n",
            "(Donald Trump): Let me tell you, my high-speed rail plan will be the envy of the world. We're talking about trains that are so fast, they'll make your head spin. *I confidently point to the audience* Picture this: gold-plated trains with luxury amenities, creating jobs and making America great again!\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 7\n",
            "\tKanye West bid: 8\n",
            "\tElizabeth Warren bid: 9\n",
            "Selected: Elizabeth Warren\n",
            "\n",
            "\n",
            "(Elizabeth Warren): *As I lean forward with a determined expression, I continue to address the audience.* My vision for transcontinental high-speed rail goes beyond luxury and extravagance. We need a system that prioritizes the needs of everyday Americans, connecting communities and providing affordable, reliable transportation options. Let's invest in a rail network that serves the people, not just the wealthy elite. *I raise my hand in a fist, symbolizing unity and strength.*\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 7\n",
            "\tKanye West bid: 2\n",
            "\tElizabeth Warren bid: 2\n",
            "Selected: Donald Trump\n",
            "\n",
            "\n",
            "(Donald Trump): Let me tell you, folks, my high-speed rail plan is going to be tremendous. We're talking about trains that go faster than you've ever seen before. *I gesture dramatically with my hands* It's going to revolutionize travel and boost our economy like never before. Believe me!\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 2\n",
            "\tKanye West bid: 8\n",
            "\tElizabeth Warren bid: 8\n",
            "Selected: Elizabeth Warren\n",
            "\n",
            "\n",
            "(Elizabeth Warren): *As I stand with unwavering determination, I address the audience with passion.* My fellow Americans, envision a transcontinental high-speed rail system that not only connects major cities but also prioritizes environmental sustainability and economic equality. Picture trains powered by renewable energy, offering affordable fares for all. Let's build a rail network that uplifts every American.\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 7\n",
            "\tKanye West bid: 2\n",
            "\tElizabeth Warren bid: 2\n",
            "Selected: Donald Trump\n",
            "\n",
            "\n",
            "(Donald Trump): Let me tell you, my high-speed rail plan will be the talk of the town. We're talking trains that break speed records and redefine luxury travel. *I make grand gestures with my hands* Imagine trains with onboard casinos, gourmet dining, and entertainment fit for a king. It's going to be huge!\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 2\n",
            "\tKanye West bid: 8\n",
            "\tElizabeth Warren bid: 8\n",
            "Selected: Elizabeth Warren\n",
            "\n",
            "\n",
            "(Elizabeth Warren): *As I stand with unwavering determination, I address the audience with passion.* My fellow Americans, envision a transcontinental high-speed rail system that not only connects major cities but also prioritizes environmental sustainability and economic equality. Picture trains powered by renewable energy, offering affordable fares for all. Let's build a rail network that uplifts every American.\n",
            "\n",
            "\n",
            "Bids:\n",
            "\tDonald Trump bid: 2\n",
            "\tKanye West bid: 2\n",
            "\tElizabeth Warren bid: 1\n",
            "Selected: Kanye West\n",
            "\n",
            "\n",
            "(Kanye West): *As I step forward with confidence, I bring a new perspective to the table.* Yo, my high-speed rail plan is next level! Imagine trains with interactive art installations, music performances, and sustainable energy sources. It's not just transportation; it's a moving cultural experience. Let's push boundaries and inspire through innovation!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "max_iters = 10\n",
        "n = 0\n",
        "\n",
        "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
        "simulator.reset()\n",
        "simulator.inject(\"Debate Moderator\", specified_topic)\n",
        "print(f\"(Debate Moderator): {specified_topic}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "while n < max_iters:\n",
        "    name, message = simulator.step()\n",
        "    print(f\"({name}): {message}\")\n",
        "    print(\"\\n\")\n",
        "    n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qcC0hgGvGDbd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}