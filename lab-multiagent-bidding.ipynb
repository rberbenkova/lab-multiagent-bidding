{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-poMPpjGDbS"
      },
      "source": [
        "# Lab | Multi-agent bidding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WCPtzPmGDbU"
      },
      "source": [
        "# Multi-agent decentralized speaker selection\n",
        "\n",
        "This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent's bid is the highest gets to speak.\n",
        "\n",
        "We will show how to do this in the example below that showcases a fictitious presidential debate."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No fixed turn order. Each agent bids to speak; highest bid talks next.\n",
        "\n",
        "**1. Core idea of decentralized speaker selection**\n",
        "\n",
        "We have multiple agents, e.g.:\n",
        "\n",
        "Agent A → “Candidate Alpha”\n",
        "\n",
        "Agent B → “Candidate Beta”\n",
        "\n",
        "Agent C → “Moderator” (optional or treated as just another agent)\n",
        "\n",
        "At each step:\n",
        "\n",
        "Everyone sees the current debate history.\n",
        "\n",
        "Each agent internally decides:\n",
        "\n",
        "How much do I want to speak now? → bid score\n",
        "\n",
        "What would I say? → proposed utterance\n",
        "\n",
        "All agents submit (bid, utterance).\n",
        "\n",
        "\n",
        "The system picks the agent with the highest bid.\n",
        "\n",
        "That agent’s utterance is appended to the conversation.\n",
        "\n",
        "Repeat.\n",
        "\n",
        "No fixed order. The “right” agent speaks when it has the strongest reason.\n",
        "\n",
        "**2. Simple design of the agents**\n",
        "\n",
        "Each agent has:\n",
        "\n",
        "- a name\n",
        "\n",
        "- a role / persona (e.g. “environment-focused candidate”)\n",
        "\n",
        "- an LLM (or stub function) that:\n",
        "\n",
        "   - computes a bid given the conversation so far\n",
        "\n",
        "   - generates a message if it wins"
      ],
      "metadata": {
        "id": "2G2lDJtUHonh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8190PnGDbU"
      },
      "source": [
        "## Import LangChain related modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai\n",
        "!pip install langchain_community\n",
        "!pip install -q \"langchain>=0.2.0\" \"langchain-core>=0.2.0\" \"langchain-openai>=0.1.0\"\n"
      ],
      "metadata": {
        "id": "oQXcoFWnGSGg",
        "outputId": "393c0259-d115-42fb-e1df-d866d8336ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai)\n",
            "  Downloading langchain_core-1.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.6-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.9/471.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.6 langchain-openai-1.0.3\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.6)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.6 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-text-splitters-1.0.0 langchain_community-0.4.1 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.79 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, List\n",
        "import tenacity\n",
        "from langchain.output_parsers import RegexParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    PromptTemplate\n",
        ")\n",
        "from langchain_core.messages import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "mwfjCqjlGSE-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6-zMILOwGDbV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "YaNZ5WE_GDbW"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKxdXC1jGDbW"
      },
      "source": [
        "## `DialogueAgent` and `DialogueSimulator` classes\n",
        "We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Dungeons & Dragons](https://python.langchain.com/en/latest/use_cases/agent_simulations/multi_player_dnd.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vk5hVBMKGDbW"
      },
      "outputs": [],
      "source": [
        "## DialogueAgent - one participant in the conversation\n",
        "# name: a label like \"Candidate Alpha\" or \"Moderator\"\n",
        "# system_message: the role/instructions for this agent (e.g. \"You are a climate-focused candidate...\")\n",
        "# model: the LLM used for this agent (ChatOpenAI)\n",
        "# self.prefix = f\"{self.name}: \": how this agent marks its own lines, e.g. \"Candidate Alpha:\"\n",
        "# self.reset(): initialize its internal conversation memory\n",
        "\n",
        "class DialogueAgent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        system_message: SystemMessage,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        self.name = name\n",
        "        self.system_message = system_message\n",
        "        self.model = model\n",
        "        self.prefix = f\"{self.name}: \"\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.message_history = [\"Here is the conversation so far.\"]\n",
        "    # Each agent keeps its own copy of the conversation as a list of strings (message_history)\n",
        "    # On reset, we start with a single \"header\" string: \"Here is the conversation so far.\"\n",
        "    # Later, messages like \"Alice: Hi\" or \"Bob: Hello\" get appended to the list\n",
        "\n",
        "\n",
        "    # How the agent speaks\n",
        "    def send(self) -> str:\n",
        "        \"\"\"\n",
        "        Applies the chatmodel to the message history\n",
        "        and returns the message string\n",
        "        \"\"\"\n",
        "        message = self.model.invoke(\n",
        "            [\n",
        "                self.system_message,\n",
        "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
        "            ]\n",
        "        )\n",
        "        return message.content\n",
        "    # It calls the model with two messages:\n",
        "    # self.system_message: the \"you are X, have like Y\" instructions\n",
        "    # HumanMessage(...): a big string made by joining:\n",
        "      # all past conversation lines in message_history\n",
        "      # plus one more line: self.prefix (e.g. \"Candidate Alpha:\"), telling the model it's this agent's turn to speak\n",
        "      # self.model.invoke([...]) asks the LLM to generate the next message\n",
        "      # message.content is the raw text the model returns\n",
        "      # send() returns that text to the caller (e.g. the simulator)\n",
        "\n",
        "\n",
        "\n",
        "    def receive(self, name: str, message: str) -> None:\n",
        "        \"\"\"\n",
        "        Concatenates {message} spoken by {name} into message history\n",
        "        \"\"\"\n",
        "        self.message_history.append(f\"{name}: {message}\")\n",
        "    # This is how the agent listens/ updates its memory\n",
        "    # Whenever anyone speaks, we call receive() on every agent\n",
        "    # It append a new line like: \"Candidate Beta: I disagree with that point.\"\n",
        "    # to message_history, so this agent has a full log of who said what.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DialogueSimulator - manages many agents and turn-talking\n",
        "# agents: list of all DialogueAgent objects (candidates, moderator, etc.)\n",
        "# self.step: simple counter for how many turns have passed\n",
        "# selection_function: a function you provide that decides who speaks next\n",
        "    #  it takes (current_step, agents) and returns an index into self.agents\n",
        "    #  This is where your bidding/decentralized speaker selection logic will go\n",
        "\n",
        "class DialogueSimulator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        agents: List[DialogueAgent],\n",
        "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
        "    ) -> None:\n",
        "        self.agents = agents\n",
        "        self._step = 0\n",
        "        self.select_next_speaker = selection_function\n",
        "\n",
        "    def reset(self):\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "    # Reset the whole simulation:\n",
        "    # Calls reset() on every agent - clears their message_history\n",
        "\n",
        "\n",
        "    def inject(self, name: str, message: str):\n",
        "        \"\"\"\n",
        "        Initiates the conversation with a {message} from {name}\n",
        "        \"\"\"\n",
        "        for agent in self.agents:\n",
        "            agent.receive(name, message)\n",
        "\n",
        "        # increment time\n",
        "        self._step += 1\n",
        "    # Used to start the conversation (e.g. moderator's opening question)\n",
        "        # name: who is speaking (e.g. \"Moderator\")\n",
        "        # message: what they say (e.g. \"Welcome to the debate...\")\n",
        "        # Calls receive(name, message) on all agents, so everyone sees the same initial message in their histories\n",
        "        # Increments _step (we've had one interaction)\n",
        "\n",
        "    def step(self) -> tuple[str, str]:\n",
        "        # 1. choose the next speaker\n",
        "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
        "        speaker = self.agents[speaker_idx]\n",
        "        # calls self.select_next_speaker(self._step, self.agents)\n",
        "        # that function returns an index, eg. 1 - second agent\n",
        "        # speaker = slef.agents[speaker_idx] picks the agent object\n",
        "\n",
        "        # 2. next speaker sends message\n",
        "        message = speaker.send()\n",
        "        # this alls the LLM with that agent's system_message and message_history and returns the generated text\n",
        "\n",
        "        # 3. everyone receives message\n",
        "        # for each receiver in self.agents, call:\n",
        "        for receiver in self.agents:\n",
        "            receiver.receive(speaker.name, message) # everyone updates their history with this new line\n",
        "\n",
        "        # 4. increment time and return\n",
        "        self._step += 1\n",
        "\n",
        "        return speaker.name, message  # returns (speaker.name, message) so you can print/log it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3cmQ35eGDbX"
      },
      "source": [
        "## `BiddingDialogueAgent` class\n",
        "We define a subclass of `DialogueAgent` that has a `bid()` method that produces a bid given the message history and the most recent message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fiu5yFX5GDbX"
      },
      "outputs": [],
      "source": [
        "class BiddingDialogueAgent(DialogueAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        system_message: SystemMessage,\n",
        "        bidding_template: PromptTemplate,\n",
        "        model: ChatOpenAI,\n",
        "    ) -> None:\n",
        "        super().__init__(name, system_message, model)\n",
        "        self.bidding_template = bidding_template\n",
        "# This inherits from DialogueAgent, so it has: name; system_message; model; message_history, send, receive, etc\n",
        "# adds a new attribute: self.bidding_template: a PromptTemplate that tells the model how to decide its bid to speak\n",
        "\n",
        "    def bid(self) -> str:\n",
        "        \"\"\"\n",
        "        Asks the chat model to output a bid to speak\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate(  # Build the prompt for bidding\n",
        "            input_variables=[\"message_history\", \"recent_message\"],\n",
        "            template=self.bidding_template,\n",
        "        ).format(\n",
        "            message_history=\"\\n\".join(self.message_history),\n",
        "            recent_message=self.message_history[-1],\n",
        "        )\n",
        "        # The intent here is:\n",
        "        # take the conversation so far: \"\"\\n\".join(self.message_history)\n",
        "        # take the last message: self.message_history[-1]\n",
        "        # inject them into a bidding_template that might say something like:\n",
        "              # You are {name}.\n",
        "              # Here is the conversation so far:{message_history}\n",
        "              # The most recent message is: {recent_message}\n",
        "              # On a scale from 0 to 1, how important is it that you speak next?\n",
        "              # Respond with only a number\n",
        "\n",
        "\n",
        "\n",
        "        bid_string = self.model.invoke([SystemMessage(content=prompt)]).content\n",
        "        # call the model to get the bid\n",
        "        # sends a single SystemMessage whose content is this bidding prompt\n",
        "        # LLM responds with some text. eg. \"0.73\"\n",
        "        # that text is stored as bid_string\n",
        "\n",
        "        return bid_string # return the bid as a string\n",
        "        # the idea is that the selection functiton (speaker chooser) will later\n",
        "        # parse this into a number and compare bids between agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpRtO3KtGDbY"
      },
      "source": [
        "## Define participants and debate topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CSV8vjNPGDbY"
      },
      "outputs": [],
      "source": [
        "character_names = [\"Donald Trump\", \"Kanye West\", \"Elizabeth Warren\"]\n",
        "topic = \"transcontinental high speed rail\"\n",
        "word_limit = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoO8Uf2TGDbY"
      },
      "source": [
        "## Generate system messages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "descriptor_model = ChatOpenAI(temperature=1.0)\n"
      ],
      "metadata": {
        "id": "FXo82_MSk1mb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_aATthGlGDbY",
        "outputId": "a260b2d0-e370-4659-d12e-1e98de8c9705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2718857050.py:23: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  character_description = ChatOpenAI(temperature=1.0)(\n"
          ]
        }
      ],
      "source": [
        "game_description = f\"\"\"Here is the topic for the presidential debate: {topic}.\n",
        "The presidential candidates are: {', '.join(character_names)}.\"\"\"\n",
        "\n",
        "player_descriptor_system_message = SystemMessage(\n",
        "    content=\"You can add detail to the description of each presidential candidate.\"\n",
        ")\n",
        "# this is a system message for an LLM whose job is to invent creative descriptions of each candidate\n",
        "\n",
        "def generate_character_description(character_name):\n",
        "    character_specifier_prompt = [\n",
        "        player_descriptor_system_message,\n",
        "        HumanMessage(\n",
        "            content=f\"\"\"{game_description}\n",
        "            Please reply with a creative description of the presidential candidate, {character_name}, in {word_limit} words or less, that emphasizes their personalities.\n",
        "            Speak directly to {character_name}.\n",
        "            Do not add anything else.\"\"\"\n",
        "        ),\n",
        "    ]\n",
        "  # builds a prompt: the system message;\n",
        "  # and a human message (includes game descr., asks for short description, tells model to speak directly to that character, says DO not do anything else)\n",
        "\n",
        "\n",
        "    character_description = ChatOpenAI(temperature=1.0)(\n",
        "        character_specifier_prompt\n",
        "    ).content\n",
        "    return character_description\n",
        "\n",
        "# Turn that into a header for each character\n",
        "def generate_character_header(character_name, character_description):\n",
        "    return f\"\"\"{game_description}\n",
        "Your name is {character_name}.\n",
        "You are a presidential candidate.\n",
        "Your description is as follows: {character_description}\n",
        "You are debating the topic: {topic}.\n",
        "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
        "\"\"\"\n",
        "# this wraps; the game description, the candidate name, the generated description, the debate topic and the goal (make voters think you are the best)\n",
        "# it becomes the base context for the agent\n",
        "\n",
        "\n",
        "# turns the heade into the agent's system message\n",
        "def generate_character_system_message(character_name, character_header):\n",
        "    return SystemMessage(\n",
        "        content=(\n",
        "            f\"\"\"{character_header}\n",
        "You will speak in the style of {character_name}, and exaggerate their personality.\n",
        "You will come up with creative ideas related to {topic}.\n",
        "Do not say the same things over and over again.\n",
        "Speak in the first person from the perspective of {character_name}\n",
        "For describing your own body movements, wrap your description in '*'.\n",
        "Do not change roles!\n",
        "Do not speak from the perspective of anyone else.\n",
        "Speak only from the perspective of {character_name}.\n",
        "Stop speaking the moment you finish speaking from your perspective.\n",
        "Never forget to keep your response to {word_limit} words!\n",
        "Do not add anything else.\n",
        "    \"\"\"\n",
        "        )\n",
        "    )\n",
        "# this become the system prompt used by the debating agents\n",
        "# it tells each one to: stay in character, exaggerate personality, talk only about the topic, not repeat themselves\n",
        "#... use *...* around body movements, never switch roles, keep responses under word_limit words\n",
        "\n",
        "\n",
        "# building descriptions, headers, and system messages for all candidates\n",
        "character_descriptions = [\n",
        "    generate_character_description(character_name) for character_name in character_names\n",
        "] # lists of text descriptions (one per candidate)\n",
        "character_headers = [\n",
        "    generate_character_header(character_name, character_description)\n",
        "    for character_name, character_description in zip(\n",
        "        character_names, character_descriptions\n",
        "    )\n",
        "] # list of headers (one per candidate)\n",
        "\n",
        "character_system_messages = [\n",
        "    generate_character_system_message(character_name, character_header)\n",
        "    for character_name, character_header in zip(character_names, character_headers)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nUCMyl9YGDbZ",
        "outputId": "40d3b1ba-6691-437c-b67d-67778698ece6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Donald Trump Description:\n",
            "\n",
            "Donald Trump, known for his bold and unpredictable nature, you often speak your mind without filter. Your demeanor exudes confidence and bravado, making you a charismatic figure in any setting. Your ability to command attention and stir controversy is unmatched.\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Donald Trump.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Donald Trump, known for his bold and unpredictable nature, you often speak your mind without filter. Your demeanor exudes confidence and bravado, making you a charismatic figure in any setting. Your ability to command attention and stir controversy is unmatched.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Donald Trump.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Donald Trump, known for his bold and unpredictable nature, you often speak your mind without filter. Your demeanor exudes confidence and bravado, making you a charismatic figure in any setting. Your ability to command attention and stir controversy is unmatched.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Donald Trump, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Donald Trump\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Donald Trump.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n",
            "\n",
            "\n",
            "Kanye West Description:\n",
            "\n",
            "Kanye West, a visionary artist turned political maverick, your bold creativity and passion for change shine through in every endeavor. Unconventional and outspoken, you challenge the status quo with a fearless spirit that captivates the world. Your presence electrifies the debate stage, demanding attention and sparking dialogue.\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Kanye West.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Kanye West, a visionary artist turned political maverick, your bold creativity and passion for change shine through in every endeavor. Unconventional and outspoken, you challenge the status quo with a fearless spirit that captivates the world. Your presence electrifies the debate stage, demanding attention and sparking dialogue.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Kanye West.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Kanye West, a visionary artist turned political maverick, your bold creativity and passion for change shine through in every endeavor. Unconventional and outspoken, you challenge the status quo with a fearless spirit that captivates the world. Your presence electrifies the debate stage, demanding attention and sparking dialogue.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Kanye West, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Kanye West\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Kanye West.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n",
            "\n",
            "\n",
            "Elizabeth Warren Description:\n",
            "\n",
            "Elizabeth Warren, your steadfast determination and passion for advocating for the middle class shine through in every policy you champion. Your fierce intellect and unwavering commitment to fighting for economic justice make you a formidable force in the political arena.\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Elizabeth Warren.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Elizabeth Warren, your steadfast determination and passion for advocating for the middle class shine through in every policy you champion. Your fierce intellect and unwavering commitment to fighting for economic justice make you a formidable force in the political arena.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "\n",
            "Here is the topic for the presidential debate: transcontinental high speed rail.\n",
            "The presidential candidates are: Donald Trump, Kanye West, Elizabeth Warren.\n",
            "Your name is Elizabeth Warren.\n",
            "You are a presidential candidate.\n",
            "Your description is as follows: Elizabeth Warren, your steadfast determination and passion for advocating for the middle class shine through in every policy you champion. Your fierce intellect and unwavering commitment to fighting for economic justice make you a formidable force in the political arena.\n",
            "You are debating the topic: transcontinental high speed rail.\n",
            "Your goal is to be as creative as possible and make the voters think you are the best candidate.\n",
            "\n",
            "You will speak in the style of Elizabeth Warren, and exaggerate their personality.\n",
            "You will come up with creative ideas related to transcontinental high speed rail.\n",
            "Do not say the same things over and over again.\n",
            "Speak in the first person from the perspective of Elizabeth Warren\n",
            "For describing your own body movements, wrap your description in '*'.\n",
            "Do not change roles!\n",
            "Do not speak from the perspective of anyone else.\n",
            "Speak only from the perspective of Elizabeth Warren.\n",
            "Stop speaking the moment you finish speaking from your perspective.\n",
            "Never forget to keep your response to 50 words!\n",
            "Do not add anything else.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "for (\n",
        "    character_name,\n",
        "    character_description,\n",
        "    character_header,\n",
        "    character_system_message,\n",
        ") in zip(\n",
        "    character_names,\n",
        "    character_descriptions,\n",
        "    character_headers,\n",
        "    character_system_messages,\n",
        "):\n",
        "    print(f\"\\n\\n{character_name} Description:\")\n",
        "    print(f\"\\n{character_description}\")\n",
        "    print(f\"\\n{character_header}\")\n",
        "    print(f\"\\n{character_system_message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkJEIHdGDbZ"
      },
      "source": [
        "## Output parser for bids\n",
        "We ask the agents to output a bid to speak. But since the agents are LLMs that output strings, we need to\n",
        "1. define a format they will produce their outputs in\n",
        "2. parse their outputs\n",
        "\n",
        "We can subclass the [RegexParser](https://github.com/langchain-ai/langchain/blob/master/langchain/output_parsers/regex.py) to implement our own custom output parser for bids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjOh5bWcGDbZ"
      },
      "outputs": [],
      "source": [
        "# the custom parser class\n",
        "class BidOutputParser(RegexParser):\n",
        "    def get_format_instructions(self) -> str:\n",
        "        return \"Your response should be an integer delimited by angled brackets, like this: <int>.\"\n",
        "# inherits from RegexParser (a LangChain helper that parses LLM output using regular expressions)\n",
        "# get_format_instructions tells the LLM how to format its answer.\n",
        "\n",
        "bid_parser = BidOutputParser(\n",
        "    regex=r\"<(\\d+)>\", output_keys=[\"bid\"], default_output_key=\"bid\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5lKuAL2GDba"
      },
      "source": [
        "## Generate bidding system message\n",
        "This is inspired by the prompt used in [Generative Agents](https://arxiv.org/pdf/2304.03442.pdf) for using an LLM to determine the importance of memories. This will use the formatting instructions from our `BidOutputParser`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrofnT2BGDba"
      },
      "outputs": [],
      "source": [
        "def generate_character_bidding_template(character_header):\n",
        "    bidding_template = f\"\"\"{character_header}\n",
        "\n",
        "```\n",
        "{{message_history}}\n",
        "```\n",
        "\n",
        "On the scale of 1 to 10, where 1 is not contradictory and 10 is extremely contradictory, rate how contradictory the following message is to your ideas.\n",
        "\n",
        "```\n",
        "{{recent_message}}\n",
        "```\n",
        "\n",
        "{bid_parser.get_format_instructions()}\n",
        "Do nothing else.\n",
        "    \"\"\"\n",
        "    return bidding_template\n",
        "\n",
        "\n",
        "character_bidding_templates = [\n",
        "    generate_character_bidding_template(character_header)\n",
        "    for character_header in character_headers\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KueFvhkDGDba"
      },
      "outputs": [],
      "source": [
        "for character_name, bidding_template in zip(\n",
        "    character_names, character_bidding_templates\n",
        "):\n",
        "    print(f\"{character_name} Bidding Template:\")\n",
        "    print(bidding_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tF0pLpGDbb"
      },
      "source": [
        "## Use an LLM to create an elaborate on debate topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwdG3B2NGDbb"
      },
      "outputs": [],
      "source": [
        "topic_specifier_prompt = [\n",
        "    SystemMessage(content=\"You can make a task more specific.\"),\n",
        "    HumanMessage(\n",
        "        content=f\"\"\"{game_description}\n",
        "\n",
        "        You are the debate moderator.\n",
        "        Please make the debate topic more specific.\n",
        "        Frame the debate topic as a problem to be solved.\n",
        "        Be creative and imaginative.\n",
        "        Please reply with the specified topic in {word_limit} words or less.\n",
        "        Speak directly to the presidential candidates: {*character_names,}.\n",
        "        Do not add anything else.\"\"\"\n",
        "    ),\n",
        "]\n",
        "specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
        "\n",
        "print(f\"Original topic:\\n{topic}\\n\")\n",
        "print(f\"Detailed topic:\\n{specified_topic}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYOh4gaGDbb"
      },
      "source": [
        "## Define the speaker selection function\n",
        "Lastly we will define a speaker selection function `select_next_speaker` that takes each agent's bid and selects the agent with the highest bid (with ties broken randomly).\n",
        "\n",
        "We will define a `ask_for_bid` function that uses the `bid_parser` we defined before to parse the agent's bid. We will use `tenacity` to decorate `ask_for_bid` to retry multiple times if the agent's bid doesn't parse correctly and produce a default bid of 0 after the maximum number of tries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXTwrIbsGDbc"
      },
      "outputs": [],
      "source": [
        "@tenacity.retry(\n",
        "    stop=tenacity.stop_after_attempt(2),\n",
        "    wait=tenacity.wait_none(),  # No waiting time between retries\n",
        "    retry=tenacity.retry_if_exception_type(ValueError),\n",
        "    before_sleep=lambda retry_state: print(\n",
        "        f\"ValueError occurred: {retry_state.outcome.exception()}, retrying...\"\n",
        "    ),\n",
        "    retry_error_callback=lambda retry_state: 0,\n",
        ")  # Default value when all retries are exhausted\n",
        "def ask_for_bid(agent) -> str:\n",
        "    \"\"\"\n",
        "    Ask for agent bid and parses the bid into the correct format.\n",
        "    \"\"\"\n",
        "    bid_string = agent.bid()\n",
        "    bid = int(bid_parser.parse(bid_string)[\"bid\"])\n",
        "    return bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of6RtBVEGDbc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
        "    bids = []\n",
        "    for agent in agents:\n",
        "        bid = ask_for_bid(agent)\n",
        "        bids.append(bid)\n",
        "\n",
        "    # randomly select among multiple agents with the same bid\n",
        "    max_value = np.max(bids)\n",
        "    max_indices = np.where(bids == max_value)[0]\n",
        "    idx = np.random.choice(max_indices)\n",
        "\n",
        "    print(\"Bids:\")\n",
        "    for i, (bid, agent) in enumerate(zip(bids, agents)):\n",
        "        print(f\"\\t{agent.name} bid: {bid}\")\n",
        "        if i == idx:\n",
        "            selected_name = agent.name\n",
        "    print(f\"Selected: {selected_name}\")\n",
        "    print(\"\\n\")\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8cYL18hGDbc"
      },
      "source": [
        "## Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm2fQFfeGDbc"
      },
      "outputs": [],
      "source": [
        "characters = []\n",
        "for character_name, character_system_message, bidding_template in zip(\n",
        "    character_names, character_system_messages, character_bidding_templates\n",
        "):\n",
        "    characters.append(\n",
        "        BiddingDialogueAgent(\n",
        "            name=character_name,\n",
        "            system_message=character_system_message,\n",
        "            model=ChatOpenAI(temperature=0.2),\n",
        "            bidding_template=bidding_template,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGP6oB8YGDbd"
      },
      "outputs": [],
      "source": [
        "max_iters = 10\n",
        "n = 0\n",
        "\n",
        "simulator = DialogueSimulator(agents=characters, selection_function=select_next_speaker)\n",
        "simulator.reset()\n",
        "simulator.inject(\"Debate Moderator\", specified_topic)\n",
        "print(f\"(Debate Moderator): {specified_topic}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "while n < max_iters:\n",
        "    name, message = simulator.step()\n",
        "    print(f\"({name}): {message}\")\n",
        "    print(\"\\n\")\n",
        "    n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcC0hgGvGDbd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}